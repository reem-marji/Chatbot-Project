{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from model_handler import OPENAI_API_KEY\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "index_name = 'v1-index-pinecone'\n",
    "text_field = \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index(index_name)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "pinecone.init(api_key=\"681591b9-096b-4da3-8df2-9de5f89fba34\", environment=\"northamerica-northeast1-gcp\")\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embeddings.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "query = \"can I visit the campus\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "response = qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\cme_project\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OPENAI_API_KEY' from partially initialized module 'model_handler' (most likely due to a circular import) (c:\\Workspace\\CME_Internship\\git_llm\\model_handler.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Workspace\\CME_Internship\\git_llm\\v1_inference.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Workspace/CME_Internship/git_llm/v1_inference.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel_handler\u001b[39;00m \u001b[39mimport\u001b[39;00m return_ai_response, initialize_model\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/CME_Internship/git_llm/v1_inference.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mvector_store\u001b[39;00m \u001b[39mimport\u001b[39;00m intialize_vector_store\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Workspace/CME_Internship/git_llm/v1_inference.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlookups\u001b[39;00m \u001b[39mimport\u001b[39;00m LLM_MODEL_TYPE\n",
      "File \u001b[1;32mc:\\Workspace\\CME_Internship\\git_llm\\model_handler.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# import os\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# import pinecone\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# from langchain.llms import OpenAI\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# from langchain import PromptTemplate, LLMChain\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# from langchain.chains import ConversationChain\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# from langchain.chains.conversation.memory import ConversationBufferMemory\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcryptography\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfernet\u001b[39;00m \u001b[39mimport\u001b[39;00m Fernet\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mvector_store\u001b[39;00m \u001b[39mimport\u001b[39;00m intialize_vector_store\n\u001b[0;32m      9\u001b[0m \u001b[39m# from langchain.vectorstores import Pinecone\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m# from langchain.embeddings.openai import OpenAIEmbeddings\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchat_models\u001b[39;00m \u001b[39mimport\u001b[39;00m ChatOpenAI\n",
      "File \u001b[1;32mc:\\Workspace\\CME_Internship\\git_llm\\vector_store.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvectorstores\u001b[39;00m \u001b[39mimport\u001b[39;00m Pinecone\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpinecone\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel_handler\u001b[39;00m \u001b[39mimport\u001b[39;00m OPENAI_API_KEY\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchat_models\u001b[39;00m \u001b[39mimport\u001b[39;00m ChatOpenAI\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'OPENAI_API_KEY' from partially initialized module 'model_handler' (most likely due to a circular import) (c:\\Workspace\\CME_Internship\\git_llm\\model_handler.py)"
     ]
    }
   ],
   "source": [
    "from model_handler import return_ai_response, initialize_model\n",
    "from vector_store import vectorstore\n",
    "from lookups import LLM_MODEL_TYPE\n",
    "\n",
    "question = \"can I visit the campus\"\n",
    "\n",
    "llm_model = initialize_model(LLM_MODEL_TYPE.GPT.value)\n",
    "response = return_ai_response(llm_model, question, vectorstore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can visit the campus. You can arrange a visit through your recruitment coordinator or student support team. Depending on your reasons for visiting, we can also arrange to meet you when you arrive on campus.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cme_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
